{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "poetry = []\n",
    "tf_word = {}\n",
    "with open('poetry.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        line = re.sub('（\\S+）', '', line)\n",
    "        line = re.sub('_', '', line)\n",
    "        poetry += re.split('[，。！？；]', line.strip())[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "five_words_poetry = list(filter(lambda x: len(x)==5, poetry))\n",
    "seven_words_poetry = list(filter(lambda x: len(x)==7, poetry))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['寒随穷律变', '春逐鸟声开', '初风飘带柳', '晚雪间花梅', '碧林青旧竹']\n",
      "['暧暧去尘昏灞岸', '飞飞轻盖指河梁', '云峰衣结千重叶', '雪岫花开几树妆', '深悲黄鹤孤舟远']\n"
     ]
    }
   ],
   "source": [
    "print(five_words_poetry[:5], seven_words_poetry[:5], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "五言诗诗句总数:296827，七言诗诗句总数:142637\n"
     ]
    }
   ],
   "source": [
    "print('五言诗诗句总数:{}，七言诗诗句总数:{}'.format(len(five_words_poetry), len(seven_words_poetry)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['寒', '随', '穷', '律', '变']\n",
      "['春', '逐', '鸟', '声', '开']\n",
      "['初', '风', '飘', '带', '柳']\n",
      "['晚', '雪', '间', '花', '梅']\n",
      "['碧', '林', '青', '旧', '竹']\n",
      "['绿', '沼', '翠', '新', '苔']\n",
      "['芝', '田', '初', '雁', '去']\n",
      "['绮', '树', '巧', '莺', '来']\n",
      "['晚', '霞', '聊', '自', '怡']\n",
      "['初', '晴', '弥', '可', '喜']\n"
     ]
    }
   ],
   "source": [
    "word_seq = []\n",
    "for line in five_words_poetry:\n",
    "    word_seq.append([word for word in line])\n",
    "print(*word_seq[:10], sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding:\n",
    "    def __init__(self, sentences, word_vec_size):\n",
    "        self.sentences = sentences\n",
    "        self.word_vec_size = word_vec_size\n",
    "        \n",
    "        self.model = None\n",
    "        self.embedding_matrix = None\n",
    "        \n",
    "        self._word2idx = {}\n",
    "        \n",
    "    def word2idx(self, word):\n",
    "        if self.model is None:\n",
    "            raise NameError('No model, use mk_embedding first.')\n",
    "        return self._word2idx[word]\n",
    "    \n",
    "    def idx2word(self, i):\n",
    "        if self.model is None:\n",
    "            raise NameError('No model, use mk_embedding first.')\n",
    "        return self.model.wv.index2word[i]\n",
    "    \n",
    "    def mk_embedding(self, load_model_path=None, save_model_path=None):\n",
    "        if load_model_path is not None:\n",
    "            model = Word2Vec.load(load_model_path)\n",
    "        else:\n",
    "            print('Word2Vec training ...')\n",
    "            model = Word2Vec(self.sentences, size=self.word_vec_size, window=5, min_count=20, workers=12, iter=10, sg=1)\n",
    "            if save_model_path is not None:\n",
    "                model.save(save_model_path)\n",
    "            else:\n",
    "                model.save('embedding/{}_word2vec.model'.format(self.word_vec_size))\n",
    "        \n",
    "        self.model = model\n",
    "        self.embedding_matrix = model.wv.vectors\n",
    "        for i, word in enumerate(model.wv.index2word):\n",
    "            self._word2idx[word] = i\n",
    "            \n",
    "        print('Embedding OK.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding OK.\n"
     ]
    }
   ],
   "source": [
    "embedding = Embedding(word_seq, 250)\n",
    "embedding.mk_embedding(load_model_path='embedding/200_word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_seq = []\n",
    "for line in word_seq:\n",
    "    try:\n",
    "        idx_seq.append([embedding.word2idx(word) for word in line])\n",
    "    except KeyError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[47, 163, 282, 1106, 514]\n",
      "[17, 406, 126, 69, 90]\n",
      "[171, 5, 452, 352, 238]\n",
      "[164, 116, 179, 23, 666]\n",
      "[267, 88, 55, 143, 160]\n",
      "[236, 1701, 280, 76, 472]\n",
      "[1166, 325, 171, 299, 36]\n",
      "[829, 73, 1510, 714, 12]\n",
      "[164, 372, 747, 22, 1976]\n",
      "[171, 388, 1120, 82, 475]\n",
      "用于训练的诗句数:289275\n"
     ]
    }
   ],
   "source": [
    "print(*idx_seq[:10], sep='\\n')\n",
    "print('用于训练的诗句数:{}'.format(len(idx_seq)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, embedding_matrix, hidden_size, num_words, num_layers=1, dropout=0, fix_embedding=False):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(*embedding_matrix.shape)\n",
    "        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix))\n",
    "        self.embedding.weight.requires_grad = True if fix_embedding is True else False\n",
    "\n",
    "        self.rnn = nn.GRU(embedding_matrix.shape[1], hidden_size, num_layers,\n",
    "                          dropout=dropout, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        self.classifier = nn.Sequential(nn.Dropout(0.2),\n",
    "                                        nn.Linear(hidden_size*2, hidden_size*4),\n",
    "                                        nn.ReLU(),\n",
    "                                        \n",
    "                                        nn.Dropout(0.2),\n",
    "                                        nn.Linear(hidden_size*4, hidden_size*8),\n",
    "                                        nn.ReLU(),\n",
    "                                        \n",
    "                                        nn.Linear(hidden_size*8, num_words),\n",
    "                                        )\n",
    "        \n",
    "    def forward(self, input):\n",
    "        # input shape is (batch_size, sequence_len, word_size)\n",
    "        # hidden shape is (batch_size, num_directions*num_layers, hidden_size)\n",
    "        embedding_seq = self.embedding(input[:,:-1])\n",
    "        output, _ = self.rnn(embedding_seq, None)\n",
    "        pred = self.classifier(output)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class PoetryDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.x[i], self.y[i]\n",
    "    \n",
    "def x2y(x):\n",
    "    y = [line[1:] for line in x]\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(x2y(idx_seq))\n",
    "x = np.array(idx_seq)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.25)\n",
    "\n",
    "train_set = DataLoader(PoetryDataset(x_train, y_train), batch_size=128)\n",
    "val_set = DataLoader(PoetryDataset(x_val, y_val), batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 10\n",
    "hidden_size = 250\n",
    "num_words = len(embedding.model.wv.index2word)\n",
    "device = torch.device('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total parameters:12795738\n"
     ]
    }
   ],
   "source": [
    "model = RNN(embedding.embedding_matrix, hidden_size, num_words, num_layers=1)\n",
    "model = model.to(device=device)\n",
    "print('total parameters:{}'.format(sum(p.numel() for p in model.parameters())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-4)\n",
    "calc_loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_acc(pred, y):\n",
    "    correct = np.sum(np.argmax(pred.detach().cpu().numpy(), axis=1) == y.detach().cpu().numpy())\n",
    "    return correct / (pred.shape[0] * 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[01/10] time:21.76(sec) train_loss:3.36429 train_acc:0.50251 | val_loss:1.68713 val_acc:0.74634\n",
      "epoch:[02/10] time:21.55(sec) train_loss:1.59696 train_acc:0.75046 | val_loss:1.51435 val_acc:0.76229\n",
      "epoch:[03/10] time:21.53(sec) train_loss:1.46550 train_acc:0.76201 | val_loss:1.44932 val_acc:0.76833\n",
      "epoch:[04/10] time:21.54(sec) train_loss:1.37806 train_acc:0.76900 | val_loss:1.41288 val_acc:0.77203\n",
      "epoch:[05/10] time:21.53(sec) train_loss:1.29864 train_acc:0.77475 | val_loss:1.39545 val_acc:0.77483\n",
      "epoch:[06/10] time:21.54(sec) train_loss:1.22386 train_acc:0.77967 | val_loss:1.39565 val_acc:0.77661\n",
      "epoch:[07/10] time:21.60(sec) train_loss:1.15382 train_acc:0.78511 | val_loss:1.41028 val_acc:0.77746\n",
      "epoch:[08/10] time:21.61(sec) train_loss:1.08877 train_acc:0.79049 | val_loss:1.43025 val_acc:0.77795\n",
      "epoch:[09/10] time:21.56(sec) train_loss:1.02848 train_acc:0.79685 | val_loss:1.45945 val_acc:0.77829\n",
      "epoch:[10/10] time:21.64(sec) train_loss:0.97365 train_acc:0.80294 | val_loss:1.49815 val_acc:0.77809\n"
     ]
    }
   ],
   "source": [
    "loss = []\n",
    "acc = []\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    start_time = time.time()\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    val_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    \n",
    "    model.train()\n",
    "    for data in train_set:\n",
    "        x = data[0].to(dtype=torch.long, device=device)\n",
    "        y = data[1].to(dtype=torch.long, device=device)\n",
    "        # y shape is (batch, seq)\n",
    "    \n",
    "        pred = model(x).transpose(1, 2)\n",
    "        # pred shape should be (batch, categories_prob, seq)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        batch_loss = calc_loss(pred, y)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += batch_loss / len(train_set)\n",
    "        train_acc += calc_acc(pred, y) / len(train_set)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in val_set:\n",
    "            x = data[0].to(dtype=torch.long, device=device)\n",
    "            y = data[1].to(dtype=torch.long, device=device)\n",
    "            \n",
    "            pred = model(x).transpose(1, 2)\n",
    "            batch_loss = calc_loss(pred, y)\n",
    "            \n",
    "            val_loss += batch_loss / len(val_set)\n",
    "            val_acc += calc_acc(pred, y) / len(val_set)\n",
    "            \n",
    "    loss.append(val_loss)\n",
    "    acc.append(val_acc)\n",
    "            \n",
    "    print('epoch:[{:02d}/{:02d}] time:{:2.2f}(sec) train_loss:{:2.5f} train_acc:{:2.5f} | val_loss:{:2.5f} val_acc:{:2.5f}'.format(epoch+1, num_epoch, time.time() - start_time, train_loss, train_acc, val_loss, val_acc)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator:\n",
    "    def __init__(self, model, data, embedding):\n",
    "        self.model = model \n",
    "        self.data = data\n",
    "        self.embedding = embedding\n",
    "    \n",
    "    def generate(self, diff, num_sample):\n",
    "        \"\"\"\n",
    "        diff: the difference generated verse between original verse\n",
    "        \"\"\"\n",
    "        i = random.sample(range(self.data.shape[0]), num_sample)\n",
    "        x = torch.tensor(self.data[i,:], dtype=torch.long, device=device)\n",
    "        original = [list(map(self.embedding.idx2word, line)) for line in x]\n",
    "        first_words = [list(map(self.embedding.idx2word, line))[0] for line in x.detach().cpu().numpy()]\n",
    "        pred = model(x)\n",
    "        pred = np.argsort(pred.detach().cpu().numpy(), axis=2)[:,:,::-1]\n",
    "        pred = [pred[:,:,diff] for _ in range(num_sample)][0]\n",
    "        return original, [[first_word] + list(map(self.embedding.idx2word, line)) for first_word, line in zip(first_words, pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(model, x_val, embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原诗:\t\t\t\t生成诗：\n",
      "['数', '骑', '射', '雕', '还']\t['数', '骑', '射', '雕', '戈']\n",
      "['若', '是', '效', '真', '人']\t['若', '是', '效', '真', '者']\n",
      "['疏', '淡', '若', '平', '郊']\t['疏', '淡', '若', '平', '生']\n",
      "['松', '江', '流', '其', '旁']\t['松', '江', '流', '其', '间']\n",
      "['浅', '处', '定', '无', '金']\t['浅', '处', '定', '无', '涯']\n",
      "['石', '洼', '泉', '似', '掬']\t['石', '洼', '泉', '似', '乳']\n",
      "['夜', '归', '书', '满', '床']\t['夜', '归', '书', '满', '堂']\n",
      "['仪', '形', '尚', '相', '对']\t['仪', '形', '尚', '相', '诡']\n",
      "['云', '阴', '无', '尽', '时']\t['云', '阴', '无', '尽', '时']\n",
      "['歌', '屏', '朝', '掩', '翠']\t['歌', '屏', '朝', '掩', '映']\n"
     ]
    }
   ],
   "source": [
    "original, generate = generator.generate(0, 10)\n",
    "print(\"原诗:\\t\\t\\t\\t生成诗：\")\n",
    "for i,j in zip(original, generate):\n",
    "    print(\"{}\\t{}\".format(i, j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.687125563621521, 1.5143505334854126, 1.4493180513381958, 1.4128762483596802, 1.395445466041565, 1.3956495523452759, 1.4102805852890015, 1.4302494525909424, 1.4594509601593018, 1.4981504678726196]\n"
     ]
    }
   ],
   "source": [
    "print([float(x) for x in loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7463356484304202, 0.7622927790310712, 0.7683285354679037, 0.7720308852606012, 0.7748275109312867, 0.7766077657915754, 0.7774616370374816, 0.7779524837119295, 0.7782913647132536, 0.77809443266148]\n"
     ]
    }
   ],
   "source": [
    "print([float(x) for x in acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_loss = [2.21130, 0.59737, 0.22049, 0.09952, 0.05811]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_acc = [0.48622, 0.83870, 0.93754, 0.97106, 0.98294]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_loss = [0.49929, 0.10409, 0.04856, 0.02982, 0.02033]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_acc = [0.88243, 0.97167, 0.98583, 0.99135, 0.99393]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = [stack_loss, bi_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = pd.DataFrame(np.array(loss).T, columns=['Encoder-Decoder','AutoEncoder'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = sns.lineplot(data=l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "picture = fig.get_figure()\n",
    "picture.savefig('StackedvsBi2.png', dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
